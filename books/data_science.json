[
  {
    "n": 1,
    "title": "Introduction to Data Science",
    "math": "Statistics",
    "note": "This section provides a high-level overview of data science as an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data to drive business value."
  },
  {
    "n": 2,
    "title": "The Data Science Process: CRISP-DM",
    "math": "Process flow models",
    "note": "This lesson introduces a standard process model for data science projects, CRISP-DM. It outlines the six major phases: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment."
  },
  {
    "n": 3,
    "title": "The Data Science Toolkit: Python and SQL",
    "math": "Logic",
    "note": "Introduces the dominant programming languages for data science. It covers Python and its core libraries (NumPy, Pandas, Scikit-learn, Matplotlib) for analysis and modeling, and SQL for data retrieval from relational databases."
  },
  {
    "n": 4,
    "title": "Data Acquisition: SQL Fundamentals",
    "math": "Relational algebra",
    "note": "This lesson covers the basics of using SQL to query data from databases. It explains the fundamental clauses: `SELECT` (to choose columns), `FROM` (to specify tables), `WHERE` (to filter rows), `GROUP BY` (to aggregate data), and `JOIN` (to combine tables)."
  },
  {
    "n": 5,
    "title": "Data Acquisition: Web Scraping and APIs",
    "math": "HTTP requests",
    "note": "This lesson covers methods for gathering data from the web. It provides a conceptual overview of how to interact with web APIs to get structured data (like JSON) and the basics of web scraping to extract information directly from HTML web pages."
  },
  {
    "n": 6,
    "title": "Data Wrangling with Pandas",
    "math": "Data transformation",
    "note": "Explains data wrangling (or data munging) as the process of cleaning, structuring, and enriching raw data. The lesson focuses on using the Pandas library in Python for common tasks like handling missing values, filtering rows, and creating new columns."
  },
  {
    "n": 7,
    "title": "Exploratory Data Analysis (EDA)",
    "math": "Descriptive statistics",
    "note": "This lesson introduces Exploratory Data Analysis (EDA), the critical process of performing initial investigations on data to discover patterns, spot anomalies, and test hypotheses. It covers using summary statistics and visualization to understand the dataset."
  },
  {
    "n": 8,
    "title": "Data Visualization Principles",
    "math": "Data visualization",
    "note": "Covers the fundamentals of effective data visualization. The lesson introduces common chart types (bar, line, scatter, histogram) and best practices for creating clear and informative plots using libraries like Matplotlib and Seaborn."
  },
  {
    "n": 9,
    "title": "Feature Engineering",
    "math": "Data transformation",
    "note": "Explains the crucial process of feature engineering, which involves creating new, more informative features from existing data to improve model performance. The lesson covers techniques like one-hot encoding for categorical variables and feature scaling."
  },
  {
    "n": 10,
    "title": "Introduction to Machine Learning",
    "math": "Machine learning",
    "note": "Provides an introduction to the core concepts of machine learning. The lesson explains the difference between supervised learning (classification, regression), unsupervised learning (clustering), and the general goal of building models that can learn from data."
  },
  {
    "n": 11,
    "title": "The Machine Learning Workflow with Scikit-Learn",
    "math": "Machine learning",
    "note": "This section introduces Scikit-learn, the primary machine learning library in Python. It covers the standard workflow: splitting data into training and testing sets, creating a model instance, training it with `.fit()`, and making predictions with `.predict()`."
  },
  {
    "n": 12,
    "title": "Supervised Learning: Regression",
    "math": "Linear regression",
    "note": "Focuses on regression, a supervised learning task for predicting a continuous numerical value. The lesson covers Linear Regression as a fundamental regression algorithm and how to evaluate its performance with metrics like Mean Squared Error (MSE)."
  },
  {
    "n": 13,
    "title": "Supervised Learning: Classification",
    "math": "Classification models",
    "note": "This lesson introduces classification, a supervised learning task for predicting a categorical label. It covers Logistic Regression and Decision Trees as fundamental classification algorithms. The concept of a confusion matrix, precision, and recall for evaluation is also introduced."
  },
  {
    "n": 14,
    "title": "Unsupervised Learning: Clustering",
    "math": "Cluster analysis",
    "note": "This section introduces clustering, an unsupervised learning task for finding natural groupings in data. It covers the most popular clustering algorithm, K-Means, and the challenge of interpreting the resulting clusters."
  },
  {
    "n": 15,
    "title": "Dimensionality Reduction with PCA",
    "math": "Linear algebra",
    "note": "This lesson introduces dimensionality reduction as a technique for reducing the number of features in a dataset. It covers Principal Component Analysis (PCA) as a common method for projecting data to a lower-dimensional space while preserving as much variance as possible."
  },
  {
    "n": 16,
    "title": "Introduction to Deep Learning",
    "math": "Artificial Neural Networks",
    "note": "This lesson provides a high-level, conceptual introduction to deep learning. It explains why it's powerful for unstructured data (like images and text) and introduces the basic components of a neural network (neurons, layers). Key libraries like TensorFlow and PyTorch are mentioned."
  },
  {
    "n": 17,
    "title": "Introduction to Natural Language Processing (NLP)",
    "math": "Computational linguistics",
    "note": "This lesson introduces the basics of working with text data. It covers fundamental NLP concepts like tokenization, stop-word removal, and vectorization (e.g., Bag-of-Words). A simple application like sentiment analysis is used as an example."
  },
  {
    "n": 18,
    "title": "Experimentation and A/B Testing",
    "math": "Hypothesis testing, statistical significance",
    "note": "This lesson covers a core data science activity in industry. It explains the principles of A/B testing: formulating a hypothesis, creating control and treatment groups, and using statistical tests to determine if a change has a real, significant effect on a key metric."
  },
  {
    "n": 19,
    "title": "Big Data Concepts: Hadoop and Spark",
    "math": "Distributed computing",
    "note": "This lesson provides a high-level overview of the big data ecosystem. It explains why these tools are necessary (when data volume, velocity, or variety exceeds the capacity of a single machine) and the basic roles of HDFS for distributed storage and Spark for distributed processing."
  },
  {
    "n": 20,
    "title": "Model Deployment and MLOps",
    "math": "ML Operations",
    "note": "This lesson completes the data science lifecycle by introducing model deployment. It covers the concept of exposing a trained model as an API so other applications can use it for predictions. It also defines the broader field of MLOps (Machine Learning Operations) for managing this entire process."
  },
  {
    "n": 21,
    "title": "Communicating Data Science Results",
    "math": "Communication theory",
    "note": "This final section emphasizes the importance of effectively communicating the results of a data science project. It covers the art of data storytelling and how to present findings to both technical and non-technical audiences using tools like Jupyter Notebooks or dedicated dashboarding software."
  }
]
